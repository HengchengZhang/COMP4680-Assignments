{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "109eb905",
      "metadata": {
        "id": "109eb905"
      },
      "source": [
        "# AML 2022 Tutorial: Introduction to PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4d6e9dff",
      "metadata": {
        "id": "4d6e9dff"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98bb74ea",
      "metadata": {
        "id": "98bb74ea"
      },
      "source": [
        "## Tensors and Operations on Tensors\n",
        "\n",
        "### Tensors\n",
        "\n",
        "They are similar to numpy arrays with only one data type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "89a4eead",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89a4eead",
        "outputId": "2aae41aa-42da-48c1-bdf5-66071aba04d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([[1,  2, 3], \n",
        "                  [4., 5, 6]])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e70853ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e70853ea",
        "outputId": "1180ddef-fb33-4fb5-9515-9b25e4764991"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d09fc660",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d09fc660",
        "outputId": "b421858e-7d6b-4c10-dba8-a7eae7a33531"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52a9e5bd",
      "metadata": {
        "id": "52a9e5bd"
      },
      "source": [
        "**Exercise 1:** Create a tensor `A` of shape `(4, 3)`, whose elements are drawn from the standard normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "65afcfee",
      "metadata": {
        "id": "65afcfee"
      },
      "outputs": [],
      "source": [
        "# Answer to Exercise 1\n",
        "A = torch.randn(4,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82e041e6",
      "metadata": {
        "id": "82e041e6"
      },
      "source": [
        "### Tensor operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fb2dc186",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb2dc186",
        "outputId": "90f88eb1-a636-40ec-c2b7-e93773c681ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2., 3., 4.],\n",
              "        [5., 6., 7.]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Element-wise operations\n",
        "# e.g., add 1 to all elements of x\n",
        "x + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8cf359b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cf359b4",
        "outputId": "548dbd58-1f0c-4586-ace0-5466f0cfa972"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 4.],\n",
              "        [2., 5.],\n",
              "        [3., 6.]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transpose of a matrix\n",
        "x.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7eab03f6",
      "metadata": {
        "id": "7eab03f6"
      },
      "outputs": [],
      "source": [
        "# Define another tensor\n",
        "y = torch.tensor([[3., 4, 2], \n",
        "                  [1 , 3, 6]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e42923e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e42923e6",
        "outputId": "90c45fa6-7463-4a71-e167-f9072713f9e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.3333, 0.5000, 1.5000],\n",
              "        [4.0000, 1.6667, 1.0000]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Element-wise operations\n",
        "# Must ensure x and y have the same shape\n",
        "assert x.shape == y.shape\n",
        "x / y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6f0fbd0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f0fbd0b",
        "outputId": "3b1d0ebd-6061-4d90-8865-7f701aae083e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[17., 25.],\n",
              "        [44., 55.]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dot product/matrix multiplication\n",
        "assert x.shape[1] == y.T.shape[0]\n",
        "x @ y.T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2afff8fb",
      "metadata": {
        "id": "2afff8fb"
      },
      "source": [
        "**Exercise 2:** Create two tensors `a` and `b` each of shape `(3, 4, 2)` and tensor `c` with shape `(3, 2, 5)`, all of which are random numbers drawn from the standard normal distribution. Then perform the following:\n",
        "1. Element-wise multiply `a` and `b` together. You should have a tensor of shape `(3, 4, 2)`.\n",
        "2. Multiply the resulting matrix with `c`, keeping the first dimension unchanged. You should have a tensor of shape `(3, 4, 5)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5b0f31e8",
      "metadata": {
        "id": "5b0f31e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 4, 5])\n"
          ]
        }
      ],
      "source": [
        "# Answer to Exercise 2\n",
        "a = torch.randn(3, 4, 2)\n",
        "b = torch.randn(3, 4, 2)\n",
        "c = torch.randn(3, 2, 5)\n",
        "ab = torch.mul(a, b)\n",
        "abc = torch.bmm(ab, c)\n",
        "print(abc.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "882ee55e",
      "metadata": {
        "id": "882ee55e"
      },
      "source": [
        "## Automatic differentiation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "1052fd1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1052fd1e",
        "outputId": "1f7ac9c8-8c72-4d64-face-a61fd557a034"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([[1., 2., 3.]], requires_grad=True)\n",
        "x.grad is None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b1325993",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1325993",
        "outputId": "fff67534-dac5-4e64-cfe9-7453bdb9fc67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2., 4., 6.]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = torch.sum(x ** 2)\n",
        "y.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c9059644",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 5., 16., 33.]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y2 = torch.sum(x ** 3)\n",
        "y2.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ef996063",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef996063",
        "outputId": "4f9177c2-7058-46c6-f027-4d6ba4beb0bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[2., 4., 6.]]),)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Equivalent way, although less used\n",
        "from torch.autograd import grad\n",
        "x = torch.tensor([[1., 2., 3.]], requires_grad=True)\n",
        "y = torch.sum(x ** 2)\n",
        "g = grad(y, x)\n",
        "g"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00f863b6",
      "metadata": {
        "id": "00f863b6"
      },
      "source": [
        "Torch can also take the gradient with respect to more than one variable. In the below example, we have a function `z = f(x, y)` and can find the gradient of `z` with respect to `x` and to `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "4aecf2c3",
      "metadata": {
        "id": "4aecf2c3"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([[1., 2, 3], [4, 5, 6]],\n",
        "                     requires_grad=True)\n",
        "y = torch.tensor([[6., 5, 4], [3, 2, 1]],\n",
        "                     requires_grad=True)\n",
        "# Frobenius norm: sum of squares of a matrix's entries\n",
        "z = torch.linalg.norm(x @ y.T, ord=\"fro\")\n",
        "\n",
        "z.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3b48fc85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b48fc85",
        "outputId": "3165673c-0de3-4cdb-9f4c-e84c713c4fba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2.3671, 1.9128, 1.4585],\n",
              "        [6.2404, 5.0330, 3.8256]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7aeb873d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aeb873d",
        "outputId": "9e50f0c9-9435-42e5-d857-e9c31b3776b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[3.8256, 5.0330, 6.2404],\n",
              "        [1.4585, 1.9128, 2.3671]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d293c25b",
      "metadata": {
        "id": "d293c25b"
      },
      "source": [
        "**Exercise 3:** You're given the matrix `A` of shape `(3, 4)` and two vectors `x` and `y` of shapes `(3,)` and `(4,)`, respectively. Consider the function of `x` and `y`:\n",
        "$$\n",
        "z = f(x, y) = x^\\top A y.\n",
        "$$\n",
        "What is $\\frac{\\partial z}{\\partial x}$ and $\\frac{\\partial z}{\\partial y}$? Use the code below to check if your solution is correct?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e02558ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e02558ec",
        "outputId": "7105004f-4802-4f3d-cece-d43d70bf2def"
      },
      "outputs": [],
      "source": [
        "# Do not change this code\n",
        "torch.random.seed = 100\n",
        "A = torch.rand(3, 4)\n",
        "x = torch.rand(3, requires_grad=True)\n",
        "y = torch.rand(4, requires_grad=True)\n",
        "z = x.T @ A @ y\n",
        "z.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ed3c025e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "ed3c025e",
        "outputId": "b9f9cdb5-bdf5-4e44-d602-d8239c8ef854"
      },
      "outputs": [],
      "source": [
        "# Answer to Exercise 3\n",
        "x_grad = x.grad  # Replace with the actual gradient\n",
        "assert torch.allclose(x_grad, x.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "50e14c9a",
      "metadata": {
        "id": "50e14c9a"
      },
      "outputs": [],
      "source": [
        "# Answer to Exercise 3\n",
        "y_grad = y.grad  # Replace with the actual gradient\n",
        "assert torch.allclose(y_grad, y.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00fc02fc",
      "metadata": {
        "id": "00fc02fc"
      },
      "source": [
        "## Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "d1bdf7cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106,
          "referenced_widgets": [
            "8dcd65c9a7414ddeba0b007d6023489d",
            "6ca8fcb80f6844818ccbc2c19925298c",
            "7e08bfa21e2048828ffd3ec3d7623aa1",
            "cee8c7f9ff4e45ce9c469760b27d8eee",
            "c95f9e1f565b43e2b994ab63a81b966c",
            "7a55954e5913439e94cac0b281badb54",
            "8881184ffcdf44f8ac0e5b30e27a78e1",
            "61c3f72fc5cb46cf9bb5b9061f1a65d2",
            "a6bce9600f6447cb99688f0d29d43297",
            "da2f449a99054336bc0cddce298d916e",
            "5b6c357aefb94c6e83dfa68f45117bcd"
          ]
        },
        "id": "d1bdf7cf",
        "outputId": "31c04ba9-82b7-4ebf-e460-06b60923c856"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7291, 16, 16)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download the dataset and transform the features\n",
        "from torchvision.datasets import USPS\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize\n",
        "transform  = Compose([ToTensor(), lambda x: x / 255])\n",
        "train_data = USPS(root=\"./\", train=True, download=True, \n",
        "                  transform=transform)\n",
        "train_data.data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "65e80ef6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65e80ef6",
        "outputId": "a236fc0b-dd99-46a6-a7b2-24b91596db3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[6, 5, 4, 7, 3]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.targets[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "a0e093e7",
      "metadata": {
        "id": "a0e093e7"
      },
      "outputs": [],
      "source": [
        "# Create a data loader\n",
        "from torch.utils.data import DataLoader\n",
        "trainloader = DataLoader(train_data, shuffle=True, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90a4d44f",
      "metadata": {
        "id": "90a4d44f"
      },
      "source": [
        "**Exercise 4:** Download the _test_ data using the same transformation and create a `testloader` with the same batch size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "334961d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "45f527e0bad34dd1b058e20d3825be1c",
            "a654ab27d2a34de5a8a53047e90072cb",
            "5d66b8dcdde948a2b7ed3a332d322878",
            "b86ed1d2d97b43fdbeec1d965f68a13e",
            "d93b572576db404dbc1e6568261c99da",
            "b44ebe3fb5da483f9734a2f46b34452c",
            "5bc2d9e7496c468e83bb9dc7422b6283",
            "56c47d9c6801474c9cdb6a30d3177f8f",
            "ccfa32b11a56401ba51428af3195c063",
            "e93e0abfc1bb4c3a8415c79361c2094d",
            "1a5b761bf1a14406a3a830061d2b7a3f"
          ]
        },
        "id": "334961d8",
        "outputId": "7bef7cf8-1c9d-4d7b-806c-c0286c2b7291"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2007, 16, 16)\n"
          ]
        }
      ],
      "source": [
        "# Answer to Exercise 4\n",
        "test_data = USPS(root=\"./\", train=False, download=True, \n",
        "                  transform=transform)\n",
        "print(test_data.data.shape)\n",
        "testloader = DataLoader(train_data, shuffle=True, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1ba9b4b",
      "metadata": {
        "id": "e1ba9b4b"
      },
      "source": [
        "## Model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "acb87119",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acb87119",
        "outputId": "b53b0548-bc67-4771-fdd5-f0f444aaaa8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=1024, bias=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from torch import nn\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(16 * 16, 512)\n",
        "        self.fc2 = nn.Linear(512, 1024)\n",
        "        self.fc3 = nn.Linear(1024, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "model = Net()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "730af204",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "730af204",
        "outputId": "4fc63ef9-e22a-40ff-e960-12890e3d788b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Flatten(start_dim=1, end_dim=-1)\n",
            "  (1): Linear(in_features=256, out_features=512, bias=True)\n",
            "  (2): ReLU()\n",
            "  (3): Linear(in_features=512, out_features=1024, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): Linear(in_features=1024, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Equivalent way, only for sequential architectures\n",
        "from torch import nn\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(16 * 16, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(1024, 10)\n",
        ")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52b26cc1",
      "metadata": {
        "id": "52b26cc1"
      },
      "source": [
        "**Exercise 5:** Create a fully connected network with the layers in the following order:\n",
        "1. Flatten the an image\n",
        "2. Linear layer from 256 to 1,024\n",
        "3. Hyperbolic tangent activation layer\n",
        "4. Linear layer from 1,024 to 64\n",
        "5. ReLU activation layer\n",
        "6. Linear layer from 64 to 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "6e753a18",
      "metadata": {
        "id": "6e753a18"
      },
      "outputs": [],
      "source": [
        "# Answer to Exercise 5\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(16 * 16, 1024),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(1024, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 10)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fab3b33f",
      "metadata": {
        "id": "fab3b33f"
      },
      "source": [
        "## Loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "fff7d373",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fff7d373",
        "outputId": "d34dd81b-c4b4-4889-8f65-24e80cadb3d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.3236)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loss function\n",
        "from torch import nn\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "outputs = torch.tensor([[1., 2, 3], [2, 2, 4]])\n",
        "targets = torch.tensor([2, 1])\n",
        "loss_fn(outputs, targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a9767eb",
      "metadata": {
        "id": "5a9767eb"
      },
      "source": [
        "**Exercise 6:** Given two vectors `outputs` and `targets` like below, what is the mean squared error loss? Then find that loss function on the PyTorch documentation to verify if you're correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "2b384f69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b384f69",
        "outputId": "555b9265-5ff2-42b5-c58a-ef32552eeecb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Answer to Exercise 6\n",
        "outputs = torch.tensor([1., 2, 3])\n",
        "targets = torch.tensor([2 , 4, 5])\n",
        "loss_fn = nn.MSELoss()  # Replace with appropriate loss function \n",
        "loss_fn(outputs, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "3fd492be",
      "metadata": {
        "id": "3fd492be"
      },
      "outputs": [],
      "source": [
        "# Optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8193d974",
      "metadata": {
        "id": "8193d974"
      },
      "source": [
        "## Training loop and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "a4bbd28d",
      "metadata": {
        "id": "a4bbd28d"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "# Train a model using the training set\n",
        "def train(model, trainloader, loss_fn, optimizer, epochs=100,\n",
        "          device=\"cpu\"):\n",
        "    # Move model to device\n",
        "    model.to(device)\n",
        "    # Turn on training mode\n",
        "    model.train()\n",
        "\n",
        "    for i in tqdm(range(epochs)):\n",
        "        # One epoch = one full pass over data\n",
        "        for x, y in trainloader:\n",
        "            # Move data to device\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            # Predict the classes\n",
        "            outputs = model(x)\n",
        "            # Compare against the ground truth\n",
        "            loss = loss_fn(outputs, y)\n",
        "            # Find the gradients\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            # Perform gradient descent step\n",
        "            optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "7955e783",
      "metadata": {
        "id": "7955e783"
      },
      "outputs": [],
      "source": [
        "# Evaluate a model using the test set\n",
        "def test(model, testloader, device=\"cpu\"):\n",
        "    # Move model to device\n",
        "    model.to(device)\n",
        "    # Turn on evaluation mode\n",
        "    model.eval()\n",
        "    # Disable gradient calculation\n",
        "    with torch.no_grad():\n",
        "        correct, total = 0, 0\n",
        "        for x, y in testloader:\n",
        "            # Move data to device\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            # Make predictions\n",
        "            preds = model(x)\n",
        "            preds = preds.argmax(1)\n",
        "            # Count the correct predictions\n",
        "            correct += torch.sum(preds == y).item()\n",
        "            total += len(y)\n",
        "    accuracy = correct / total\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dfe5a2e",
      "metadata": {
        "id": "9dfe5a2e"
      },
      "source": [
        "## Putting everything together"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ef3aa66",
      "metadata": {
        "id": "5ef3aa66"
      },
      "source": [
        "**Exercise 7**: Use the model we defined in Exercise 5 and train it using SGD for 50 epochs. After that, what is the accuracy of our classifier on the test set?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "c068b4e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c068b4e0",
        "outputId": "6b276bf1-3f4e-4691-e9e1-87e9224a99cd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:45<00:00,  2.28s/it]\n"
          ]
        }
      ],
      "source": [
        "# Answer to Exercise 7\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(16 * 16, 1024),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(1024, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 10)\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "train(model, trainloader, loss_fn, optimizer, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "CdZ5rx-rOslr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdZ5rx-rOslr",
        "outputId": "f6fb60b3-09f7-4ef0-b97a-472c526c3375"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9325195446440817"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test(model, testloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WgLmrH86tD-h",
      "metadata": {
        "id": "WgLmrH86tD-h"
      },
      "source": [
        "## Using a GPU for faster computation\n",
        "\n",
        "For environments that support GPU acceleration, you can change the device on which you store tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "5c8af00a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c8af00a",
        "outputId": "0c797cf6-c2fe-40a9-fc60-9135fe4f1657"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Torch not compiled with CUDA enabled",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-4d5493477f27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             raise AssertionError(\n",
            "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
          ]
        }
      ],
      "source": [
        "device = \"cuda:0\"\n",
        "x = torch.randn(4, 3, device=device)\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4-bWdbJStH_I",
      "metadata": {
        "id": "4-bWdbJStH_I"
      },
      "source": [
        "Operations on tensors must be done on the same device. For example, you cannot add a tensor on a CPU with another tensor on a GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1cf1429",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "c1cf1429",
        "outputId": "1c800631-4ee7-4463-97f5-9f455eaa1591"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-dd7205fde27c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ],
      "source": [
        "x = torch.randn(4, 3, device=\"cuda:0\")\n",
        "y = torch.randn(4, 3, device=\"cpu\")\n",
        "x + y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a320e746",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a320e746",
        "outputId": "a8877350-6fef-4c57-c404-6f27da68512b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.8644, -0.9710,  1.1157],\n",
              "        [ 1.5925, -2.5518, -0.9779],\n",
              "        [ 2.1114, -0.2590, -1.1856],\n",
              "        [-0.5814, -0.3382, -1.0386]], device='cuda:0')"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = y.to(\"cuda:0\")\n",
        "x + y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E6knH7gatLrY",
      "metadata": {
        "id": "E6knH7gatLrY"
      },
      "source": [
        "You can also port an model to a GPU easily. This basically places all trainable parameters to the GPU you choose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23fb4a7d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23fb4a7d",
        "outputId": "0ca3f680-7c4e-458c-8d51-c69328f0b430"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Flatten(start_dim=1, end_dim=-1)\n",
            "  (1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "  (2): Tanh()\n",
            "  (3): Linear(in_features=1024, out_features=64, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(256, 1024),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(1024, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 10)\n",
        ")\n",
        "model.to(\"cuda:0\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9MZH3dwqtNf7",
      "metadata": {
        "id": "9MZH3dwqtNf7"
      },
      "source": [
        "**Exercise 8**: Go back to Exercise 7. Identify what else needs to be transferred to a GPU to train the model. Then repeat the training process and observe how long training takes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97695cf2",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8a12d7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8a12d7c",
        "outputId": "6ca2b43f-f8e2-4973-fb31-2aee745140d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:28<00:00,  1.40s/it]\n"
          ]
        }
      ],
      "source": [
        "# Answer to Exercise 8\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(16 * 16, 1024),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(1024, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 10)\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "train(model, trainloader, loss_fn, optimizer, epochs=20,\n",
        "      device=\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZybcByU7VIt_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZybcByU7VIt_",
        "outputId": "c3d7427b-8b49-4aef-8885-b4edfb4f36e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9374571389384172"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test(model, testloader, device=\"cuda:0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LmKtgd49tSBB",
      "metadata": {
        "id": "LmKtgd49tSBB"
      },
      "source": [
        "## Avoiding overfitting: regularization\n",
        "\n",
        "We will perform 2 ways to implement regularization: random dropout and $\\ell_2$ regularization."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WOFeEjgptUTs",
      "metadata": {
        "id": "WOFeEjgptUTs"
      },
      "source": [
        "### Dropout\n",
        "\n",
        "This will randomly zero out some neurons in a layer, and rescale the rest of the neurons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e877edd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e877edd",
        "outputId": "a0eed79b-0448-4e6a-8bfc-504f88b34b6a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:29<00:00,  1.45s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.9465093951446989"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# First, redefine the model\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(256, 1024),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(1024, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.2),\n",
        "    nn.Linear(64, 10)\n",
        ")\n",
        "# Then, define the loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "train(model, trainloader, loss_fn, optimizer, epochs=20, device=\"cuda:0\")\n",
        "test(model, testloader, device=\"cuda:0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "D6q-bB4otX54",
      "metadata": {
        "id": "D6q-bB4otX54"
      },
      "source": [
        "**Exercise 9**: Implement another dropout layer at the end of the first hidden layer, with the probability of 50%. Observe the test error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b031c3cb",
      "metadata": {
        "id": "b031c3cb"
      },
      "outputs": [],
      "source": [
        "# Answer to Exercise 9"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jVQDLazNtXnd",
      "metadata": {
        "id": "jVQDLazNtXnd"
      },
      "source": [
        "### $\\ell_2$ regularization\n",
        "\n",
        "Assume that the loss function is $f(w)$, where $w$ is the weights of our model. This regularization adds an additional term $\\frac{\\lambda}{2} \\lVert w \\rVert^2$ to $f(w)$. The effect of this is that $w$ will be driven closer to $0$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43e70ee7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43e70ee7",
        "outputId": "fb6cd6b6-0331-4109-d982-bfdbbb376aef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:28<00:00,  1.45s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.9343025648059251"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# First, redefine the model\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(256, 1024),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(1024, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 10)\n",
        ")\n",
        "# Then, define the loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, \n",
        "                             weight_decay=1e-5)\n",
        "train(model, trainloader, loss_fn, optimizer, epochs=20, \n",
        "      device=\"cuda:0\")\n",
        "test(model, testloader, device=\"cuda:0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4rPAHcg2tfzm",
      "metadata": {
        "id": "4rPAHcg2tfzm"
      },
      "source": [
        "**Exercise 10**: Try a few different values of `weight_decay` and observe the test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfc5a19c",
      "metadata": {
        "id": "dfc5a19c"
      },
      "outputs": [],
      "source": [
        "weight_decay_values = [1, 3e-1, 1e-1, 3e-2, 1e-2]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "882ee55e",
        "00fc02fc",
        "e1ba9b4b",
        "fab3b33f"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "6b55f2c5758f94475f4f7183eca0917db64713a141a094f87423d7ec135e764d"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a5b761bf1a14406a3a830061d2b7a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45f527e0bad34dd1b058e20d3825be1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a654ab27d2a34de5a8a53047e90072cb",
              "IPY_MODEL_5d66b8dcdde948a2b7ed3a332d322878",
              "IPY_MODEL_b86ed1d2d97b43fdbeec1d965f68a13e"
            ],
            "layout": "IPY_MODEL_d93b572576db404dbc1e6568261c99da"
          }
        },
        "56c47d9c6801474c9cdb6a30d3177f8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b6c357aefb94c6e83dfa68f45117bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bc2d9e7496c468e83bb9dc7422b6283": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d66b8dcdde948a2b7ed3a332d322878": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56c47d9c6801474c9cdb6a30d3177f8f",
            "max": 1831726,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ccfa32b11a56401ba51428af3195c063",
            "value": 1831726
          }
        },
        "61c3f72fc5cb46cf9bb5b9061f1a65d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ca8fcb80f6844818ccbc2c19925298c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a55954e5913439e94cac0b281badb54",
            "placeholder": "​",
            "style": "IPY_MODEL_8881184ffcdf44f8ac0e5b30e27a78e1",
            "value": ""
          }
        },
        "7a55954e5913439e94cac0b281badb54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e08bfa21e2048828ffd3ec3d7623aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61c3f72fc5cb46cf9bb5b9061f1a65d2",
            "max": 6579383,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6bce9600f6447cb99688f0d29d43297",
            "value": 6579383
          }
        },
        "8881184ffcdf44f8ac0e5b30e27a78e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dcd65c9a7414ddeba0b007d6023489d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ca8fcb80f6844818ccbc2c19925298c",
              "IPY_MODEL_7e08bfa21e2048828ffd3ec3d7623aa1",
              "IPY_MODEL_cee8c7f9ff4e45ce9c469760b27d8eee"
            ],
            "layout": "IPY_MODEL_c95f9e1f565b43e2b994ab63a81b966c"
          }
        },
        "a654ab27d2a34de5a8a53047e90072cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b44ebe3fb5da483f9734a2f46b34452c",
            "placeholder": "​",
            "style": "IPY_MODEL_5bc2d9e7496c468e83bb9dc7422b6283",
            "value": ""
          }
        },
        "a6bce9600f6447cb99688f0d29d43297": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b44ebe3fb5da483f9734a2f46b34452c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b86ed1d2d97b43fdbeec1d965f68a13e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e93e0abfc1bb4c3a8415c79361c2094d",
            "placeholder": "​",
            "style": "IPY_MODEL_1a5b761bf1a14406a3a830061d2b7a3f",
            "value": " 1831936/? [00:01&lt;00:00, 2649005.23it/s]"
          }
        },
        "c95f9e1f565b43e2b994ab63a81b966c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccfa32b11a56401ba51428af3195c063": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cee8c7f9ff4e45ce9c469760b27d8eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da2f449a99054336bc0cddce298d916e",
            "placeholder": "​",
            "style": "IPY_MODEL_5b6c357aefb94c6e83dfa68f45117bcd",
            "value": " 6580224/? [00:01&lt;00:00, 8010069.18it/s]"
          }
        },
        "d93b572576db404dbc1e6568261c99da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da2f449a99054336bc0cddce298d916e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e93e0abfc1bb4c3a8415c79361c2094d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
