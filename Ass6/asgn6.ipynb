{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>COMP4680/8650: Advanced Topics in Machine Learning</h1>\n",
    "<h2>Assignment #6: Deep Learning Programming Assignment</h2>\n",
    "Semester 2, 2022<br>\n",
    "</center>\n",
    "    \n",
    "**Due**: 11:55pm on Sunday 30 October, 2022.<br>\n",
    "Submit as a single Jupyter Notebook via Wattle. Make sure that your name and student ID appears in the section below. Cite all sources of help used outside of the PyTorch documentation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** ``(enter your full name here)``\n",
    "<br>\n",
    "**Student ID:** ``(enter your student ID here)``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In this assignment you will \n",
    "experiment with different optimisation algorithms on a (nonconvex) toy problem and\n",
    "build a simple neural network for image super resolution using a coordinate-based model.\n",
    "We will provide you with starter code using the PyTorch deep learning\n",
    "library, which can be downloaded from https://pytorch.org/. Follow the installation instructions (for\n",
    "the stable release, v1.12.1 at time of writing), being sure to install both `pytorch` and `torchvision`.\n",
    "On Windows you may need to install the `Microsoft Visual C++ Redistributable` (you will get an error\n",
    "with URL on where to find the release if not installed when you run the code below).\n",
    "Browse through some of the PyTorch user documentation and tutorials.\n",
    "\n",
    "\n",
    "**Run all code blocks from start to end (`Restart & Run All`) and then save your Jupyter Notebook\n",
    "before submitting your assignment to ensure everything works as expected.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T08:44:00.709108Z",
     "start_time": "2022-10-08T08:43:58.882763Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. From Convex Optimisation to Non-Convex Optimisation (40 marks)\n",
    "\n",
    "So far we have learned tools for convex optimisation. However deep learning is usually non-convex. While there are specialised methods for solving non-convex problems, for example alternating minimisation methods or branch-and-bound methods, many of them build on ideas from convex optimisation. Very few non-convex optimisation problems can be truly solved and we have to be content with a local minimum.\n",
    "\n",
    "In this question we will investigate different optimisation algorithms (often called optimizers in machine learning software packages). As an example we use the famous non-convex test problem called the six-hump camel function [Dizon and Szeg√∂, 1978](https://www.sfu.ca/~ssurjano/camel6.html), defined as\n",
    "\n",
    "$$\n",
    "f(x_1, x_2)=\\left( 4-2.1x_1^2+\\frac{x_1^4}{3}\\right)x_1^2 +x_1x_2 + (-4+4x_2^2)x_2^2.\n",
    "$$\n",
    "\n",
    "It has six local minima, two of which are global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T08:44:03.286980Z",
     "start_time": "2022-10-08T08:44:03.094472Z"
    }
   },
   "outputs": [],
   "source": [
    "def six_humped_camel(x1, x2):\n",
    "    # x1 and x2 are tensors of the same shape. Returns y of the same shape\n",
    "    y = (4 - 2.1 * x1**2 + x1**4 / 3) * x1**2 + \\\n",
    "        x1 * x2 + (-4 + 4 * x2**2) * x2**2\n",
    "    return y\n",
    "\n",
    "global_minima = np.array([[-0.0898,0.7126],[0.0898,-0.7126]])\n",
    "domain = np.linspace(-2,2,100)\n",
    "x_grid,y_grid = np.meshgrid(domain, domain)\n",
    "z_grid = six_humped_camel(x_grid, y_grid)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "offset = 1 - z_grid.min()\n",
    "levels = np.exp(np.linspace(0, (np.log(z_grid.max()+offset)), 40))-offset\n",
    "cm=ax.contour(x_grid, y_grid, z_grid, levels=levels, cmap=plt.cm.jet, alpha=0.5)\n",
    "plt.colorbar(cm)\n",
    "ax.set_xlabel('x_1'); ax.set_ylabel('x_2')\n",
    "ax.plot(global_minima[:,0], global_minima[:,1], 'r*', markersize=10, label=\"Global Optima\")\n",
    "plt.legend()\n",
    "plt.title('Contour plot of six-humped camel function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning problems, the non-convex parameter landscape is a function of the data and a non-convex model and/or loss, which usually decomposes over each data instance. For given data set ${\\cal D} = \\{D_1, \\ldots, D_N\\}$ and model parameters $\\mathbf{x}$ we can summarise this mathematically as\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\mathbf{x}; \\mathcal{D}) = \\frac{1}{N} \\sum_{i=1}^{N} f(\\mathbf{x}, D_i)\n",
    "$$\n",
    "\n",
    "where $f$ is the per-instance loss and the parameter landscape is the plot of the loss $\\mathcal{L}$ against parameters $\\mathbf{x}$. Here the optimisation problem is to find a value for $\\mathbf{x}$ where $\\mathcal{L}(\\mathbf{x}; {\\cal D})$ is minimal (or at least low).\n",
    "\n",
    "To make this toy problem more like such a problem, we will actually optimise the following loss\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\mathbf{x}; \\mathcal{D}) =  \\frac{1}{N} \\sum_{i=1}^{N} f(\\mathbf{x}, D_i) =  \\frac{1}{N} \\sum_{i=1}^{N} \\left( a_i+b_ix_1^2+c_ix_1^4\\right)x_1^2 +d_ix_1x_2 + (e_i+f_ix_2^2)x_2^2.\n",
    "$$\n",
    "where $D_i=(a_i, b_i, c_i, d_i, e_i, f_i)$ is the input data and $\\mathbf{x}=(x_1, x_2)$ are the parameters of the model. We will generate our data as\n",
    "\n",
    "$$\n",
    "D_i \\sim \\mathcal{N}\\left((4, -2.1, \\frac{1}{3}, 1, -4, 4), \\sigma I\\right)\n",
    "$$\n",
    "so that each instance is a perturbed six-humped camel function and optimising the expected loss over (infinite) data is equivalent to optimising for a six-humped camel function.\n",
    "\n",
    "The following plots show that the expected loss over the whole dataset is very similar to the ground truth six-humped camel function, while the expected loss over the first 10 instances looks somewhat different.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T08:44:09.270215Z",
     "start_time": "2022-10-08T08:44:09.248197Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make the data and define the loss function\n",
    "np.random.seed(1)\n",
    "mean_data = np.array([4.0,-2.1,1/3,1,-4,4])\n",
    "data = torch.tensor(np.random.randn(500,6) + mean_data) # (500,6)\n",
    "\n",
    "def loss(data, x):\n",
    "    # Given data of shape (N, 6) and x of shape (2,), computes loss for each instance of shape (N,)\n",
    "    assert len(data.shape) == 2 and data.shape[1]==6, data.shape\n",
    "    assert x.shape == (2,), x.shape\n",
    "    return (data[:,0] + data[:,1] * x[0]**2 + data[:,2]*x[0]**4) * x[0]**2 + \\\n",
    "        data[:,3]*x[0] * x[1] + (data[:,4] + data[:,5] * x[1]**2) * x[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T08:44:19.338323Z",
     "start_time": "2022-10-08T08:44:12.553864Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_vals = torch.tensor(np.stack([x_grid.reshape(-1), y_grid.reshape(-1)], axis=-1)) # (10000,2)\n",
    "\n",
    "fig2, axs = plt.subplots(1, 2, figsize=(10,4))\n",
    "z_grid_2 = torch.stack([loss(data, xy).mean() for xy in grid_vals], dim=-1).reshape(100,100).numpy()\n",
    "offset = 1 - z_grid_2.min()\n",
    "levels = np.exp(np.linspace(0, (np.log(z_grid_2.max()+offset)), 40))-offset\n",
    "cm=axs[0].contour(x_grid, y_grid, z_grid_2, levels=levels, cmap=plt.cm.jet, alpha=0.5)\n",
    "plt.colorbar(cm, ax=axs[0])\n",
    "axs[0].set_xlabel('x_1'); axs[0].set_ylabel('x_2')\n",
    "axs[0].plot(global_minima[:,0], global_minima[:,1], 'r*', markersize=10, label=\"Global Optima of true loss\")\n",
    "axs[0].legend()\n",
    "axs[0].set_title('Expected loss of our model over the data')\n",
    "\n",
    "z_grid_2 = torch.stack([loss(data[:10], xy).mean() for xy in grid_vals], dim=-1).reshape(100,100).numpy()\n",
    "offset = 1 - z_grid_2.min()\n",
    "levels = np.exp(np.linspace(0, (np.log(z_grid_2.max()+offset)), 40))-offset\n",
    "cm=axs[1].contour(x_grid, y_grid, z_grid_2, levels=levels, cmap=plt.cm.jet, alpha=0.5)\n",
    "plt.colorbar(cm, ax=axs[1])\n",
    "axs[1].set_xlabel('x_1'); axs[1].set_ylabel('x_2')\n",
    "axs[1].plot(global_minima[:,0], global_minima[:,1], 'r*', markersize=10, label=\"Global Optima of true loss\")\n",
    "axs[1].legend()\n",
    "axs[1].set_title('Expected loss of our model over data[:10]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent optimisation algorithms\n",
    "\n",
    "We will now compare multiple optimisation algorithms on this problem.\n",
    "\n",
    "- The first algorithm we will compare is __batch gradient descent (GD)__. As per the Wk 10 slides, the update is\n",
    "$$ \n",
    "x \\leftarrow x -\\eta \\nabla_x \\mathcal{L}\n",
    "$$\n",
    "where $\\eta$ is the learning rate.\n",
    "\n",
    "\n",
    "- The second algorithm we will compare to is __stochastic gradient descent (SGD)__. As per the Wk 10 slides, rather than using the whole gradient we only compute the gradient on a subset of the data, sometimes called a mini-batch, and do the descent using that gradient. On expectation the gradient will approximate the full gradient, so this method should also converge to a local minima of the expected loss of the whole dataset.\n",
    "\n",
    "\n",
    "- The third algorithm we will compare to is __SGD with momentum__. The idea behind momentum is to reduce noise in the stochastic estimation of the gradient by computing a weighted sum of previous gradient directions. The update rule is\n",
    "\\begin{align}\n",
    "v &\\leftarrow \\gamma v + \\nabla_x \\mathcal{L}\\\\\n",
    "x &\\leftarrow x - \\eta v\n",
    "\\end{align}\n",
    "where $v$ is the momentum, $\\gamma$ controls the weighting of previous gradients, and initially $v = \\nabla_x \\mathcal{L}$.\n",
    "\n",
    "\n",
    "- The fourth and fifth algorithms we will compare to are __AdaGrad and Adam__, which are covered in the Wk 10 slides.\n",
    "\n",
    "You will implement GD, SGD and SGD with momentum (a simplified version of PyTorch's implementation) and use PyTorch's implementation of AdaGrad and Adam. The first three are condensed into an optimisation class, called `CustomSGDwMomentum(params, lr, momentum)`, which takes a list of parameters, a learning rate and a momentum value. You will also complete the implementation of function `train_model(data, x, optimizer, bs, max_epochs)` which trains the parameter $x$ using the given optimizer and batch size `bs` until convergence (or until `max_epochs` has been reached). \n",
    "\n",
    "Note that GD is then implemented by having `momentum=0` and `bs` equal to the full dataset size, SGD is implemented by `momentum=0` and `bs` equal to something less than the full dataset size, and SGD with momentum is the same with non-zero momentum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Implement `CustomSGDwMomentum` and `train_model` (20 marks)\n",
    "\n",
    "Complete each `TODO` section and do not modify any other code. If you are unable to implement `CustomSGDwMomentum` then the testing code will revert to using PyTorch's SGD optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-20T00:31:52.999555Z",
     "start_time": "2022-09-20T00:31:52.984838Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomSGDwMomentum(torch.optim.Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr, momentum=0):\n",
    "        if lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if momentum < 0.0:\n",
    "            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n",
    "\n",
    "        defaults = dict(lr=lr, momentum=momentum)\n",
    "        super(CustomSGDwMomentum, self).__init__(params, defaults)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "        \n",
    "        Args:\n",
    "            closure : An optional feature for PyTorch optimizers, we will not be using it here.\n",
    "        \"\"\"\n",
    "\n",
    "        # for each different group of parameters that we specify\n",
    "        for group in self.param_groups:\n",
    "            params_with_grad = []\n",
    "            grad_list = []\n",
    "            v_list = []\n",
    "            momentum_gamma = group['momentum']\n",
    "            lr = group['lr']\n",
    "\n",
    "            # populate the list of params, grads and vs (momentums)\n",
    "            for p in group['params']:\n",
    "                if p.grad is not None:\n",
    "                    # add parameter to list of parameters to update\n",
    "                    params_with_grad.append(p)\n",
    "                    # add grad saved in that parameter to list\n",
    "                    grad_list.append(p.grad)\n",
    "                    \n",
    "                    # add momentum we have saved in that parameter's state to list\n",
    "                    if 'v' not in self.state[p]:\n",
    "                        v_list.append(torch.clone(p.grad).detach())\n",
    "                    else:\n",
    "                        v_list.append(self.state[p]['v'])\n",
    "\n",
    "            # update each param in params_with_grad with their respect grad in grad_list and\n",
    "            # momentum term in v_list\n",
    "            for i in range(len(params_with_grad)):\n",
    "                \n",
    "                ##############################################################################\n",
    "                # TODO: Implement the update rule (update v_list and params_with_grad).      #\n",
    "                # Make sure to update the parameters in params_with_grad inplace, i.e. do    #\n",
    "                # not replace them with a new tensor. One way to do this is to do            #\n",
    "                # `param += val`, note that `param = param + val` creates a new variable (or #\n",
    "                # in PyTorch a new tensor that is not an nn.Parameter) and assigns it to     #\n",
    "                # the variable named param.                                                  #\n",
    "                ##############################################################################\n",
    "                raise NotImplementedError\n",
    "\n",
    "            # Update momentum v in each param's state\n",
    "            for p, v in zip(params_with_grad, v_list):\n",
    "                self.state[p]['v'] = v\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-20T00:31:53.015171Z",
     "start_time": "2022-09-20T00:31:53.000536Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(data, x, optimizer, bs, max_epochs):\n",
    "    \"\"\"\n",
    "    Trains model with given parameters and optimizer until convergence unless it had reached max_epochs \n",
    "        data is of shape (N, D)\n",
    "        x is the parameters (P,)\n",
    "        optimizer is an initialised pytorch optimizer with parameters [x,]\n",
    "        bs is the batch size, None means the full dataset size\n",
    "        max_epochs is the maximum number of epochs to run for.\n",
    "    \"\"\"\n",
    "    \n",
    "    x_vals = []\n",
    "    loss_vals = []\n",
    "    x_vals.append(np.copy(x.detach().numpy()))\n",
    "    \n",
    "    N, _ = data.shape\n",
    "    if bs == None:\n",
    "        bs = N\n",
    "    batches_per_epoch = int(np.ceil(N/bs))\n",
    "    assert 1 <= bs <= N\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        for i in range(batches_per_epoch):\n",
    "            \n",
    "            #######################################################################################\n",
    "            # TODO: Get the mean loss over the i^th mini-batch of size bs, and take a step on x.  #\n",
    "            # Have a look at the PyTorch documentation. You will need to:                         #\n",
    "            #   1. zero the gradient by calling `zero_grad()` on the optimiser                    #\n",
    "            #   2. compute the mean loss of the current mini-batch and call it `loss_val`         #\n",
    "            #   3. compute the gradient for the loss by running `backward()`                      #\n",
    "            #   4. take a gradient step by calling `step()` on the optimiser                      #\n",
    "            #######################################################################################\n",
    "            \n",
    "            raise NotImplementedError\n",
    "            \n",
    "            # store loss of each iteration\n",
    "            loss_vals.append(loss_val.item())\n",
    "            current_x = np.copy(x.detach().numpy())\n",
    "            \n",
    "        # determine if converged by whether the parameters haven't changed\n",
    "        if np.linalg.norm(current_x - x_vals[-1]) < 1e-4:\n",
    "            break\n",
    "        # store parameter value at the end of the epoch\n",
    "        x_vals.append(current_x)\n",
    "        \n",
    "    x_vals = np.stack(x_vals, axis=0)\n",
    "    print(\"Finished after {} epochs\".format(x_vals.shape[0]))\n",
    "    return x_vals, loss_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to optimise the loss function using different optimisers. It will fail if you have not yet completed implementation of the functions above, in particular, the `train_model` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-20T00:31:53.267071Z",
     "start_time": "2022-09-20T00:31:53.016010Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train with different optimisers starting at x = [1.5, 1.5]\n",
    "\n",
    "### GD\n",
    "x = nn.Parameter(torch.tensor([1.5, 1.5]))\n",
    "try:\n",
    "    optimizer = CustomSGDwMomentum([x], lr=0.001)\n",
    "    x_vals_GD, loss_vals_GD = train_model(data, x, optimizer, bs=None, max_epochs=1000)\n",
    "except NotImplementedError:\n",
    "    # fallback if you haven't been able to implement CustomSGDwMomentum\n",
    "    optimizer = torch.optim.SGD([x], lr=0.001)\n",
    "    x_vals_GD, loss_vals_GD = train_model(data, x, optimizer, bs=None, max_epochs=1000)\n",
    "    \n",
    "### SGD\n",
    "x = nn.Parameter(torch.tensor([1.5, 1.5]))\n",
    "try:\n",
    "    optimizer = CustomSGDwMomentum([x], lr=0.001)\n",
    "    x_vals_SGD, loss_vals_SGD = train_model(data, x, optimizer, bs=30, max_epochs=1000)\n",
    "except NotImplementedError:\n",
    "    # fallback if you haven't been able to implement CustomSGDwMomentum\n",
    "    optimizer = torch.optim.SGD([x], lr=0.001)\n",
    "    x_vals_SGD, loss_vals_SGD = train_model(data, x, optimizer, bs=30, max_epochs=1000)\n",
    "\n",
    "### SGD with momentum\n",
    "x = nn.Parameter(torch.tensor([1.5, 1.5]))\n",
    "try:\n",
    "    optimizer = CustomSGDwMomentum([x], lr=0.001, momentum=0.9)\n",
    "    x_vals_SGDm, loss_vals_SGDm = train_model(data, x, optimizer, bs=30, max_epochs=1000)\n",
    "except NotImplementedError:\n",
    "    optimizer = torch.optim.SGD([x], lr=0.001, momentum=0.9) # Use this is you haven't been able to implement CustomSGDwMomentum\n",
    "    x_vals_SGDm, loss_vals_SGDm = train_model(data, x, optimizer, bs=30, max_epochs=1000)\n",
    "\n",
    "### AdaGrad\n",
    "x = nn.Parameter(torch.tensor([1.5, 1.5]))\n",
    "optimizer = torch.optim.Adagrad([x], lr=0.1)\n",
    "x_vals_AG, loss_vals_AG = train_model(data, x, optimizer, bs=30, max_epochs=1000)\n",
    "\n",
    "### Adam\n",
    "x = nn.Parameter(torch.tensor([1.5, 1.5]))\n",
    "optimizer = torch.optim.Adam([x], lr=0.1)\n",
    "x_vals_Adam, loss_vals_Adam = train_model(data, x, optimizer, bs=30, max_epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your optimisers have run to completion, execute the following code to visualise the optimisation path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-20T00:31:53.269861Z",
     "start_time": "2022-09-20T00:31:46.444Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot animation of the training\n",
    "from matplotlib import animation\n",
    "fig, ax = plt.subplots()\n",
    "offset = 1 - z_grid.min()\n",
    "levels = np.exp(np.linspace(0, (np.log(z_grid.max()+offset)), 40))-offset\n",
    "cm=ax.contour(x_grid, y_grid, z_grid, levels=levels, cmap=plt.cm.jet, alpha=0.5)\n",
    "plt.colorbar(cm)\n",
    "ax.set_xlabel('x_1'); ax.set_ylabel('x_2')\n",
    "ax.plot(global_minima[:,0], global_minima[:,1], 'r*', markersize=10, label=\"Global Optima\")\n",
    "lineGD, = ax.plot(x_vals_GD[:0,0], x_vals_GD[:0,1], 'b.-', markersize=5, label=\"GD, {} epochs\".format(x_vals_GD.shape[0]))\n",
    "lineSGD, = ax.plot(x_vals_SGD[:0,0], x_vals_SGD[:0,1], 'g.-', markersize=5, label=\"SGD, {} epochs\".format(x_vals_SGD.shape[0]))\n",
    "lineSGDm, = ax.plot(x_vals_SGDm[:0,0], x_vals_SGDm[:0,1], 'c.-', markersize=5, label=\"SGD with momentum, {} epochs\".format(x_vals_SGDm.shape[0]))\n",
    "lineAG, = ax.plot(x_vals_AG[:0,0], x_vals_AG[:0,1], 'm.-', markersize=5, label=\"Adagrad, {} epochs\".format(x_vals_AG.shape[0]))\n",
    "lineAdam, = ax.plot(x_vals_Adam[:0,0], x_vals_Adam[:0,1], 'k.-', markersize=5, label=\"Adam, {} epochs\".format(x_vals_Adam.shape[0]))\n",
    "plt.legend()\n",
    "plt.title('Contour plot of six-humped camel function')\n",
    "\n",
    "def init():\n",
    "    lineGD.set_data(x_vals_GD[:0,0], x_vals_GD[:0,1])\n",
    "    lineSGD.set_data(x_vals_SGD[:0,0], x_vals_SGD[:0,1])\n",
    "    lineSGDm.set_data(x_vals_SGDm[:0,0], x_vals_SGDm[:0,1])\n",
    "    lineAG.set_data(x_vals_AG[:0,0], x_vals_AG[:0,1])\n",
    "    lineAdam.set_data(x_vals_Adam[:0,0], x_vals_Adam[:0,1])\n",
    "\n",
    "def animate(i):\n",
    "    lineGD.set_data(x_vals_GD[:i,0], x_vals_GD[:i,1])\n",
    "    lineSGD.set_data(x_vals_SGD[:i,0], x_vals_SGD[:i,1])\n",
    "    lineSGDm.set_data(x_vals_SGDm[:i,0], x_vals_SGDm[:i,1])\n",
    "    lineAG.set_data(x_vals_AG[:i,0], x_vals_AG[:i,1])\n",
    "    lineAdam.set_data(x_vals_Adam[:i,0], x_vals_Adam[:i,1])\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init, frames=200, interval=20, blit=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Answer the following questions. Feel free to use other sources, but cite them (no style necessary, just website link etc. is enough). (10 marks)\n",
    "\n",
    "### 1.2.1: Why is SGD used instead of batch gradient descent? Give 2 reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(enter your answer here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2: Summarise the advantages of SGD with momentum, Adagrad and Adam over vanilla SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(enter your answer here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3: Gradient descent as taught in lecture 7 has a line search component. Why is line search typically not used in deep learning? We also covered a second order method, Newton's method, in lecture 7. Why are second order methods impractical for deep learning use cases, which typically have high-dimensional datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(enter your answer here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Experiment with the different optimisers with different batch sizes and starting points. Comment on how this affects the minima at which the optimsation converges at (if it converges at all), espcially whether it was able to escape close local minima and reach better minima, and why this is the case. (10 marks)\n",
    "\n",
    "To do this, you can just call the training code above in a new cell, i.e.,\n",
    "```\n",
    "x = nn.Parameter(torch.tensor([1.5, 1.5]))                                            # Change starting point here\n",
    "optimizer = CustomSGDwMomentum([x], lr=0.001, momentum=0.9)                           # Change optimiser here\n",
    "x_vals_SGDm, loss_vals_SGDm = train_model(data, x, optimizer, bs=30, max_epochs=1000) # Change batch-size here\n",
    "```\n",
    "\n",
    "You can then copy, paste and run the plotting code in a new cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(enter your answer here)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Coordinate-Based Networks (60 marks)\n",
    "\n",
    "Your task is to implement an coordinate-based network for image super resolution. Unlike standard machine learning models for computer vision where we learn over a training set of images with the goal of generialising to new images, here we optimise a single model per image with the goal of interpolating between observed pixels. Given a $W$-by-$H$ input image our goal is to learn a nerual network that maps from normalised coordinates $(u, v) \\in [0, 1] \\times [0, 1]$ to the RGB value of the pixel at that coordinate. We do this by performing stochastic gradient descent on the following objective,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\theta; \\mathcal{I}) &= \\sum_{(u, v)} \\| f_\\theta(u, v) - \\mathcal{I}(u, v) \\|\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\mathcal{I}$ is the image and $f_\\theta : \\mathbb{R}^2 \\to \\mathbb{R}^3$ is a neural network with parameters $\\theta$. During training we sample $(u, v)$ from the normalised pixel space. Once trained, we can produce a high-resolution output image by sampling $(u, v)$ at arbitrary precision.\n",
    "\n",
    "We will implement the coordinate-based network as a multi-layer perceptron (MLP). However, instead of providing raw pixel coordinates $x = (u, v)$ as input to the MLP we will first apply random frequency feature mappings, which have been shown to be effective for image reconstruction [Tanik et al., NeurIPS 2020](https://arxiv.org/abs/2006.10739). Specifically, let $B$ be a fixed 2-by-N matrix with entries sampled i.i.d. from a Gaussian ${\\cal N}(0, \\sigma^2)$. Then we compute the output colour as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y = f_\\theta(x) = \\text{MLP}_\\theta(\\sin(2\\pi B x), \\cos(2\\pi B x))\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We have provided model templates below. The MLP consists of repeated linear, leaky ReLU and batch normalisation layers. **Complete each `TODO` section and do not modify any other code.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. The Coordinate-Based Network (30 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-20T00:32:39.156837Z",
     "start_time": "2022-09-20T00:32:39.149635Z"
    }
   },
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# TODO: Complete the ImageCBN module.                                     #\n",
    "###########################################################################\n",
    "\n",
    "class ImageCBN(nn.Module):\n",
    "    \"\"\"Model to map from normalised pixel coordinates to a normalised RGB\n",
    "    colour vector.\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_list=(64,), freqs=64):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        ----------\n",
    "        hidden_list: iteratable\n",
    "            List of sizes for each hidden layer\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        None\n",
    "        \"\"\"\n",
    "        super(ImageCBN, self).__init__()\n",
    "\n",
    "        self.layers = None\n",
    "        self.B = 10.0 * torch.randn((2, freqs))\n",
    "        \n",
    "        ####################################################################\n",
    "        # TODO: Create a nn.Sequential model with layers consisting of\n",
    "        # (fully connected) linear followed by leaky ReLU and batch norm \n",
    "        # (1d version).\n",
    "        # The first linear layers input size is defined by the number of\n",
    "        # frequency features. Remember this includes both sin and cos.\n",
    "        # Subsequent linear layers have input size defined by hidden_list.\n",
    "        # The final linear layer should have output size 3. After the output\n",
    "        # use Sigmoid activation to keep the result between 0 and 1. \n",
    "        # Assign your nn.Sequence model to the variable self.layers.\n",
    "        ####################################################################\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        ----------\n",
    "        x: torch.Tensor\n",
    "            Input image coordinates of size (B, 2)\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        rgb: torch.Tensor\n",
    "            Output coordinate colour (B, 3)\n",
    "        \"\"\"\n",
    "        \n",
    "        ####################################################################\n",
    "        # TODO: Implement the foward pass for the coordinate-based network.                     #\n",
    "        ####################################################################\n",
    "        pass\n",
    "        \n",
    "        \n",
    "        return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-20T00:32:45.170684Z",
     "start_time": "2022-09-20T00:32:45.133381Z"
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY ANYTHING IN THIS BLOCK\n",
    "\n",
    "import unittest\n",
    "\n",
    "# test encoder\n",
    "class TestCBN(unittest.TestCase):\n",
    "\n",
    "    def test_size(self):\n",
    "        \"\"\"Test that ImageCBN produces the right size model.\"\"\"\n",
    "        hidden_sizes = (64, 64)\n",
    "        freq_size = 128\n",
    "\n",
    "        model = ImageCBN(hidden_sizes, freq_size)\n",
    "        self.assertEqual(model.B.size(), torch.Size([2, 128]))\n",
    "        \n",
    "        expected_input_sizes = [2 * freq_size] + list(hidden_sizes)\n",
    "        expected_output_sizes = list(hidden_sizes) + [3]\n",
    "        linear_layer_index = 0\n",
    "        for layer in model.layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                self.assertLess(linear_layer_index, len(expected_input_sizes))\n",
    "                self.assertEqual(layer.in_features, expected_input_sizes[linear_layer_index])\n",
    "                self.assertEqual(layer.out_features, expected_output_sizes[linear_layer_index])\n",
    "                linear_layer_index += 1\n",
    "        \n",
    "# run tests\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2b. Coordinate-Based Network Optimisation (30 marks)\n",
    "\n",
    "The code will run on a GPU if one is available and the appropriate cuda libraries are installed. Otherwise it will run on the CPU (and take longer for training, but should be less than 10 mins). **Make sure your code passes the unit tests above before running any of these experiments.**\n",
    "\n",
    "After running the training code answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-20T00:31:53.273359Z",
     "start_time": "2022-09-20T00:31:46.454Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "\n",
    "# Run on GPU if available. Set to False if you want to force the models\n",
    "# to stay on the CPU even if cuda is available.\n",
    "try:\n",
    "    RUN_ON_GPU = torch.cuda.is_available()\n",
    "except:\n",
    "    RUN_ON_GPU = False\n",
    "    \n",
    "# Set the random seed for reproducibility\n",
    "SEED = 4680\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if RUN_ON_GPU:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "\n",
    "def np_to_var(x):\n",
    "    \"\"\"Converts numpy to variable.\"\"\"\n",
    "    if RUN_ON_GPU:\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "\n",
    "def var_to_np(x):\n",
    "    \"\"\"Converts variable to numpy.\"\"\"\n",
    "    if RUN_ON_GPU:\n",
    "        x = x.cpu()\n",
    "    return x.data.numpy()\n",
    "\n",
    "\n",
    "def get_data_loader(img_filename, batch_size=32):\n",
    "    \"\"\"Creates training data loader.\"\"\"\n",
    "    \n",
    "    img = Image.open(img_filename).convert('RGB')\n",
    "    rgb = torchvision.transforms.functional.to_tensor(img)\n",
    "    rgb[rgb > 1.0] = 1.0\n",
    "    rgb[rgb < 0.0] = 0.0\n",
    "\n",
    "    x = torch.cartesian_prod(torch.linspace(0, 1, steps=rgb.shape[1]),\n",
    "                             torch.linspace(0, 1, steps=rgb.shape[2]))\n",
    "    \n",
    "    dataset = TensorDataset(x, rgb.view(3, -1).permute([1, 0]))    \n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# --- training code -------------------------------------------------------\n",
    "\n",
    "def create_model(hidden_list=(64,), freqs=0):\n",
    "    \"\"\"Creates the coordinate-based network model and moves to the GPU if requested.\"\"\"\n",
    "\n",
    "    model = ImageCBN(hidden_list, freqs)\n",
    "\n",
    "    if RUN_ON_GPU:\n",
    "        print('Moving models to GPU.')\n",
    "        model.cuda()\n",
    "    else:\n",
    "        print('Keeping models on CPU.')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def reconstruct_image(model, width=64, height=64, viewport=(0, 1, 0, 1)):\n",
    "    \"\"\"Reconstruct an image from the coordinate-based network model.\"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x = torch.cartesian_prod(torch.linspace(viewport[2], viewport[3], steps=height),\n",
    "                                 torch.linspace(viewport[0], viewport[1], steps=width))\n",
    "    \n",
    "        rgb = model.forward(x)\n",
    "        img = rgb.reshape((width, height, 3))\n",
    "    return img.detach()\n",
    "    \n",
    "\n",
    "def train_model(model, img_filename, batch_size=256, num_epochs=50, log_interval=10, plot_fcn=None):\n",
    "    \"\"\"Train model.\"\"\"\n",
    "\n",
    "    # create optimizer\n",
    "    objective = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "    dataloader = get_data_loader(img_filename, batch_size=batch_size)\n",
    "    total_train_iters = num_epochs * len(dataloader)\n",
    "\n",
    "    loss_history = []\n",
    "    print('Started training at {}'.format(time.asctime(time.localtime(time.time()))))\n",
    "\n",
    "    # train for num_epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        for iteration, batch in enumerate(dataloader, epoch * len(dataloader) + 1):\n",
    "\n",
    "            coords, rgb = batch\n",
    "            \n",
    "            # forward pass\n",
    "            rgb_hat = model(coords)\n",
    "                        \n",
    "            # backward pass\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss = objective(rgb_hat, rgb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # keep track of loss for plotting or printing\n",
    "            loss_history.append(loss.data.item())\n",
    "\n",
    "            # print the log info\n",
    "            if iteration % log_interval == 0:\n",
    "                if plot_fcn is None:\n",
    "                    print('Iteration [{:6d}/{:6d}] | loss: {:.4f}'.format(\n",
    "                        iteration, total_train_iters, loss_history[-1]))\n",
    "                else:\n",
    "                    model.eval()\n",
    "                    img = reconstruct_image(model, 128, 128)\n",
    "                    model.train()\n",
    "                    plot_fcn(loss_history, img, total_train_iters)\n",
    "                                \n",
    "    print('Finished training at {}'.format(time.asctime(time.localtime(time.time()))))                \n",
    "    return loss_history\n",
    "                \n",
    "# --- main ----------------------------------------------------------------\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "def plot_loss(loss, img, x_max=None):\n",
    "    \"\"\"Loss plotting.\"\"\"\n",
    "    ax[0].clear()\n",
    "    ax[0].plot(loss)\n",
    "    if x_max is not None:\n",
    "        ax[0].set_xlabel('iter. ({} of {})'.format(len(loss), x_max))\n",
    "    else:\n",
    "        ax[0].set_xlabel('iter.')\n",
    "    ax[0].set_ylabel('loss')\n",
    "    \n",
    "    ax[1].imshow(img)\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title('loss = {:0.3e}'.format(loss[-1]))\n",
    "    fig.canvas.draw()\n",
    "\n",
    "\n",
    "model = create_model((64, 64), 256)\n",
    "\n",
    "img_filename = 'mandril.png'\n",
    "loss_curve = train_model(model, img_filename, batch_size=4096, num_epochs=100, log_interval=10, plot_fcn=plot_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now evaluate the model on any viewport and any scale. For example, the code below zooms in around the right eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-20T00:31:53.274490Z",
     "start_time": "2022-09-20T00:31:46.456Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "img = imread(img_filename)\n",
    "\n",
    "model.eval()\n",
    "img1024x1024 = reconstruct_image(model, 1024, 1024, viewport=[0.4, 0.9, 0.0, 0.5])\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img[0:64, 51:115, :])\n",
    "plt.axis('off'); plt.title('original')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img1024x1024)\n",
    "plt.axis('off'); plt.title('model')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "**(a)** Calculate the number of learnable parameters in the model. Comment on this number versus the number of pixels in the original image. __(5 marks)__\n",
    "\n",
    "**(b)** What can you say about the reconstructed image? What about the zoomed in image? __(5 marks)__\n",
    "\n",
    "**(c)** Comment on what happens when you remove the frequency features and simply reconstruct the image based on raw pixel coordinates, i.e., $y = \\text{MLP}_\\theta(x)$. __(10 marks)__\n",
    "\n",
    "**(d)** Experiment with different model configurations and different learning parameters. Can you find a better model or method of training. Include your modified code in a new cell below and justify your reasoning. __(10 marks)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(TODO: enter your answer here)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-20T00:31:53.276383Z",
     "start_time": "2022-09-20T00:31:46.467Z"
    }
   },
   "outputs": [],
   "source": [
    "## TODO: Implement code for part (d).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "fdb684dd2522f8089a4a63f953c300e8b21d2b4176fb65f04dd43bff993d7831"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
